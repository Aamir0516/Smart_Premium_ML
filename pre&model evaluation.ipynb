{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f754bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06fbfbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Course\\Aamir\\project 3\\coding\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"E:\\\\Course\\\\Aamir\\\\project 3\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f95681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "      <td>1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   Age  Gender  Annual Income Marital Status  Number of Dependents  \\\n",
       "0   0  19.0  Female        10049.0        Married                   1.0   \n",
       "1   1  39.0  Female        31678.0       Divorced                   3.0   \n",
       "2   2  23.0    Male        25602.0       Divorced                   3.0   \n",
       "3   3  21.0    Male       141855.0        Married                   2.0   \n",
       "4   4  21.0    Male        39651.0         Single                   1.0   \n",
       "\n",
       "  Education Level     Occupation  Health Score  Location  ... Previous Claims  \\\n",
       "0      Bachelor's  Self-Employed     22.598761     Urban  ...             2.0   \n",
       "1        Master's            NaN     15.569731     Rural  ...             1.0   \n",
       "2     High School  Self-Employed     47.177549  Suburban  ...             1.0   \n",
       "3      Bachelor's            NaN     10.938144     Rural  ...             1.0   \n",
       "4      Bachelor's  Self-Employed     20.376094     Rural  ...             0.0   \n",
       "\n",
       "   Vehicle Age  Credit Score  Insurance Duration           Policy Start Date  \\\n",
       "0         17.0         372.0                 5.0  2023-12-23 15:21:39.134960   \n",
       "1         12.0         694.0                 2.0  2023-06-12 15:21:39.111551   \n",
       "2         14.0           NaN                 3.0  2023-09-30 15:21:39.221386   \n",
       "3          0.0         367.0                 1.0  2024-06-12 15:21:39.226954   \n",
       "4          8.0         598.0                 4.0  2021-12-01 15:21:39.252145   \n",
       "\n",
       "  Customer Feedback Smoking Status Exercise Frequency Property Type  \\\n",
       "0              Poor             No             Weekly         House   \n",
       "1           Average            Yes            Monthly         House   \n",
       "2              Good            Yes             Weekly         House   \n",
       "3              Poor            Yes              Daily     Apartment   \n",
       "4              Poor            Yes             Weekly         House   \n",
       "\n",
       "  Premium Amount  \n",
       "0         2869.0  \n",
       "1         1483.0  \n",
       "2          567.0  \n",
       "3          765.0  \n",
       "4         2022.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0 1199999\n",
      "Age 18.0 64.0\n",
      "Annual Income 1.0 149997.0\n",
      "Number of Dependents 0.0 4.0\n",
      "Health Score 2.0122371818911766 58.97591405405534\n",
      "Previous Claims 0.0 9.0\n",
      "Vehicle Age 0.0 19.0\n",
      "Credit Score 300.0 849.0\n",
      "Insurance Duration 1.0 9.0\n",
      "Premium Amount 20.0 4999.0\n"
     ]
    }
   ],
   "source": [
    "numerical_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "for i in numerical_features:\n",
    "    print(i, data[i].min(), data[i].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fe56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = data.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af95a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 599999.5\n",
      "Age 41.145563131986506\n",
      "Annual Income 32745.21777653108\n",
      "Number of Dependents 2.0099337080218063\n",
      "Health Score 25.61390769251925\n",
      "Previous Claims 1.002689088497089\n",
      "Vehicle Age 9.569888682776748\n",
      "Credit Score 592.9243502134415\n",
      "Insurance Duration 5.018219181849318\n",
      "Premium Amount 1102.5448216666666\n",
      "Gender Male\n",
      "Marital Status Single\n",
      "Education Level Master's\n",
      "Occupation Employed\n",
      "Location Suburban\n",
      "Policy Type Premium\n",
      "Policy Start Date 2020-02-08 15:21:39.134960\n",
      "Customer Feedback Average\n",
      "Smoking Status Yes\n",
      "Exercise Frequency Weekly\n",
      "Property Type House\n"
     ]
    }
   ],
   "source": [
    "for feature in numerical_features:\n",
    "    print(feature,data[feature].mean())\n",
    "# Impute categorical features with mode\n",
    "for feature in categorical_features:\n",
    "    print(feature,data[feature].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5537cf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>Rural</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>127237.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Employed</td>\n",
       "      <td>5.769783</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-08-08 15:21:39.181605</td>\n",
       "      <td>Average</td>\n",
       "      <td>No</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Condo</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>52447.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Employed</td>\n",
       "      <td>20.473718</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-08-02 15:21:39.144722</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Condo</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>6076.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Employed</td>\n",
       "      <td>7.442964</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-10-17 15:21:39.209847</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>849.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   Age  Gender  Annual Income Marital Status  Number of Dependents  \\\n",
       "0    0  19.0  Female        10049.0        Married                   1.0   \n",
       "4    4  21.0    Male        39651.0         Single                   1.0   \n",
       "7    7  48.0  Female       127237.0       Divorced                   2.0   \n",
       "9    9  44.0    Male        52447.0        Married                   2.0   \n",
       "15  15  18.0    Male         6076.0        Married                   2.0   \n",
       "\n",
       "   Education Level     Occupation  Health Score  Location  ...  \\\n",
       "0       Bachelor's  Self-Employed     22.598761     Urban  ...   \n",
       "4       Bachelor's  Self-Employed     20.376094     Rural  ...   \n",
       "7      High School       Employed      5.769783  Suburban  ...   \n",
       "9         Master's       Employed     20.473718     Urban  ...   \n",
       "15     High School       Employed      7.442964     Urban  ...   \n",
       "\n",
       "   Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \\\n",
       "0              2.0         17.0         372.0                 5.0   \n",
       "4              0.0          8.0         598.0                 4.0   \n",
       "7              1.0         11.0         398.0                 5.0   \n",
       "9              1.0          9.0         635.0                 3.0   \n",
       "15             1.0         12.0         584.0                 5.0   \n",
       "\n",
       "             Policy Start Date Customer Feedback Smoking Status  \\\n",
       "0   2023-12-23 15:21:39.134960              Poor             No   \n",
       "4   2021-12-01 15:21:39.252145              Poor            Yes   \n",
       "7   2022-08-08 15:21:39.181605           Average             No   \n",
       "9   2020-08-02 15:21:39.144722              Poor             No   \n",
       "15  2020-10-17 15:21:39.209847              Good            Yes   \n",
       "\n",
       "   Exercise Frequency Property Type Premium Amount  \n",
       "0              Weekly         House         2869.0  \n",
       "4              Weekly         House         2022.0  \n",
       "7              Rarely         Condo          111.0  \n",
       "9               Daily         Condo           64.0  \n",
       "15            Monthly     Apartment          849.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c68bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200000 entries, 0 to 1199999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   id                    1200000 non-null  int64  \n",
      " 1   Age                   1181295 non-null  float64\n",
      " 2   Gender                1200000 non-null  object \n",
      " 3   Annual Income         1155051 non-null  float64\n",
      " 4   Marital Status        1181471 non-null  object \n",
      " 5   Number of Dependents  1090328 non-null  float64\n",
      " 6   Education Level       1200000 non-null  object \n",
      " 7   Occupation            841925 non-null   object \n",
      " 8   Health Score          1125924 non-null  float64\n",
      " 9   Location              1200000 non-null  object \n",
      " 10  Policy Type           1200000 non-null  object \n",
      " 11  Previous Claims       835971 non-null   float64\n",
      " 12  Vehicle Age           1199994 non-null  float64\n",
      " 13  Credit Score          1062118 non-null  float64\n",
      " 14  Insurance Duration    1199999 non-null  float64\n",
      " 15  Policy Start Date     1200000 non-null  object \n",
      " 16  Customer Feedback     1122176 non-null  object \n",
      " 17  Smoking Status        1200000 non-null  object \n",
      " 18  Exercise Frequency    1200000 non-null  object \n",
      " 19  Property Type         1200000 non-null  object \n",
      " 20  Premium Amount        1200000 non-null  float64\n",
      "dtypes: float64(9), int64(1), object(11)\n",
      "memory usage: 192.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef33f9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "Age                      18705\n",
       "Gender                       0\n",
       "Annual Income            44949\n",
       "Marital Status           18529\n",
       "Number of Dependents    109672\n",
       "Education Level              0\n",
       "Occupation              358075\n",
       "Health Score             74076\n",
       "Location                     0\n",
       "Policy Type                  0\n",
       "Previous Claims         364029\n",
       "Vehicle Age                  6\n",
       "Credit Score            137882\n",
       "Insurance Duration           1\n",
       "Policy Start Date            0\n",
       "Customer Feedback        77824\n",
       "Smoking Status               0\n",
       "Exercise Frequency           0\n",
       "Property Type                0\n",
       "Premium Amount               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200000, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns with more than 50% missing values\n",
    "threshold = len(data) * 0.5\n",
    "data = data.dropna(thresh=threshold, axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff1f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Policy Start Date',axis=1,inplace=True)\n",
    "data.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c198ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "      <td>1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Premium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>House</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Annual Income Marital Status  Number of Dependents  \\\n",
       "0  19.0  Female        10049.0        Married                   1.0   \n",
       "1  39.0  Female        31678.0       Divorced                   3.0   \n",
       "2  23.0    Male        25602.0       Divorced                   3.0   \n",
       "3  21.0    Male       141855.0        Married                   2.0   \n",
       "4  21.0    Male        39651.0         Single                   1.0   \n",
       "\n",
       "  Education Level     Occupation  Health Score  Location    Policy Type  \\\n",
       "0      Bachelor's  Self-Employed     22.598761     Urban        Premium   \n",
       "1        Master's            NaN     15.569731     Rural  Comprehensive   \n",
       "2     High School  Self-Employed     47.177549  Suburban        Premium   \n",
       "3      Bachelor's            NaN     10.938144     Rural          Basic   \n",
       "4      Bachelor's  Self-Employed     20.376094     Rural        Premium   \n",
       "\n",
       "   Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \\\n",
       "0              2.0         17.0         372.0                 5.0   \n",
       "1              1.0         12.0         694.0                 2.0   \n",
       "2              1.0         14.0           NaN                 3.0   \n",
       "3              1.0          0.0         367.0                 1.0   \n",
       "4              0.0          8.0         598.0                 4.0   \n",
       "\n",
       "  Customer Feedback Smoking Status Exercise Frequency Property Type  \\\n",
       "0              Poor             No             Weekly         House   \n",
       "1           Average            Yes            Monthly         House   \n",
       "2              Good            Yes             Weekly         House   \n",
       "3              Poor            Yes              Daily     Apartment   \n",
       "4              Poor            Yes             Weekly         House   \n",
       "\n",
       "   Premium Amount  \n",
       "0          2869.0  \n",
       "1          1483.0  \n",
       "2           567.0  \n",
       "3           765.0  \n",
       "4          2022.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Annual Income',\n",
       " 'Marital Status',\n",
       " 'Number of Dependents',\n",
       " 'Occupation',\n",
       " 'Health Score',\n",
       " 'Previous Claims',\n",
       " 'Vehicle Age',\n",
       " 'Credit Score',\n",
       " 'Insurance Duration',\n",
       " 'Customer Feedback']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().reset_index()[data.isnull().sum().reset_index()[0] > 0] [\"index\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23cd226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Marital Status',\n",
       " 'Education Level',\n",
       " 'Occupation',\n",
       " 'Location',\n",
       " 'Policy Type',\n",
       " 'Customer Feedback',\n",
       " 'Smoking Status',\n",
       " 'Exercise Frequency',\n",
       " 'Property Type']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features=data.select_dtypes(include=['object']).columns.to_list()\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ce28f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Annual Income',\n",
       " 'Number of Dependents',\n",
       " 'Health Score',\n",
       " 'Previous Claims',\n",
       " 'Vehicle Age',\n",
       " 'Credit Score',\n",
       " 'Insurance Duration',\n",
       " 'Premium Amount']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features=data.select_dtypes(include=['int64','float64']).columns.to_list()\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Summary:\n",
      " Age                      18705\n",
      "Annual Income            44949\n",
      "Marital Status           18529\n",
      "Number of Dependents    109672\n",
      "Occupation              358075\n",
      "Health Score             74076\n",
      "Previous Claims         364029\n",
      "Vehicle Age                  6\n",
      "Credit Score            137882\n",
      "Insurance Duration           1\n",
      "Customer Feedback        77824\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify missing values\n",
    "missing_summary = data.isnull().sum()\n",
    "print(\"Missing Values Summary:\\n\", missing_summary[missing_summary > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f1c1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Column Groups\n",
    "numerical_cols = [\n",
    "    'Age', 'Annual Income', 'Number of Dependents', 'Health Score',\n",
    "    'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration'\n",
    "]\n",
    "\n",
    "ordinal_cols = ['Education Level', 'Exercise Frequency']  # Replace if not present\n",
    "nominal_cols = [\n",
    "    'Gender', 'Marital Status', 'Occupation', 'Location',\n",
    "    'Policy Type', 'Smoking Status', 'Property Type'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fdd2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Pipelines\n",
    "# Ordinal categories\n",
    "education_order = ['High School', \"Bachelor's\", \"Master's\", 'PhD']\n",
    "exercise_order = ['Rarely', 'Monthly', 'Weekly', 'Daily']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[education_order, exercise_order])\n",
    "\n",
    "# Pipelines\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', ordinal_encoder)\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59786fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine All with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('ord', ordinal_pipeline, ordinal_cols),\n",
    "    ('nom', nominal_pipeline, nominal_cols)\n",
    "], remainder='drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split and Preprocess\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['Premium Amount'])\n",
    "y = data['Premium Amount']\n",
    "\n",
    "# Fit-transform\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afb61351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEP 3: Feature Grouping\n",
    "numerical_cols = [\n",
    "    'Age', 'Annual Income', 'Number of Dependents', 'Health Score',\n",
    "    'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration'\n",
    "]\n",
    "\n",
    "ordinal_cols = ['Education Level', 'Exercise Frequency']\n",
    "# You may need to check if they're in df.columns before using\n",
    "\n",
    "nominal_cols = [\n",
    "    'Gender', 'Marital Status', 'Occupation', 'Location',\n",
    "    'Policy Type', 'Smoking Status', 'Property Type'\n",
    "]\n",
    "\n",
    "# Final target column\n",
    "target = 'Premium Amount'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47c424d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Categorical Variables\n",
    "#Ordinal Encoding\n",
    "education_order = ['High School', \"Bachelor's\", \"Master's\", 'PhD']\n",
    "exercise_order = ['Rarely', 'Monthly', 'Weekly', 'Daily']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[education_order, exercise_order])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44e9168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHot Encode Nominal\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b0bd191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: Handle Outliers in Numerical Features\n",
    "def remove_outliers_iqr(data, columns):\n",
    "    for col in columns:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        data = data[(data[col] >= lower) & (data[col] <= upper)]\n",
    "    return data\n",
    "\n",
    "# Outlier removal on numerical columns only (except target!)\n",
    "df = remove_outliers_iqr(data, numerical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', ordinal_encoder)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('ord', ordinal_pipeline, ordinal_cols),\n",
    "    ('nom', nominal_pipeline, nominal_cols)\n",
    "], remainder='drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f167220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Apply transformation\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    return {'Model': name, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fa6bbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  RMSE: 852.11\n",
      "  MAE:  657.43\n",
      "  RÂ²:   0.0025\n",
      "----------------------------------------\n",
      "Decision Tree:\n",
      "  RMSE: 1232.76\n",
      "  MAE:  907.27\n",
      "  RÂ²:   -1.0878\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "  RMSE: 850.23\n",
      "  MAE:  659.63\n",
      "  RÂ²:   0.0069\n",
      "----------------------------------------\n",
      "XGBoost:\n",
      "  RMSE: 841.97\n",
      "  MAE:  642.83\n",
      "  RÂ²:   0.0261\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    result = evaluate_model(name, model, X_test, y_test)\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c71e3c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model         RMSE         MAE        R2\n",
      "0            XGBoost   841.966543  642.834689  0.026085\n",
      "1      Random Forest   850.225677  659.628649  0.006884\n",
      "2  Linear Regression   852.114638  657.425757  0.002466\n",
      "3      Decision Tree  1232.756957  907.272161 -1.087788\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).sort_values(by='RMSE')\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y using log1p to handle skew and 0s\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Split again with log-transformed target\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(\n",
    "    X_processed, y_log, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3174d81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (log target):\n",
      "  RMSE: 926.91\n",
      "  MAE:  640.13\n",
      "  RÂ²:   -0.1803\n",
      "----------------------------------------\n",
      "Decision Tree (log target):\n",
      "  RMSE: 1224.02\n",
      "  MAE:  897.70\n",
      "  RÂ²:   -1.0583\n",
      "----------------------------------------\n",
      "Random Forest (log target):\n",
      "  RMSE: 941.65\n",
      "  MAE:  638.61\n",
      "  RÂ²:   -0.2182\n",
      "----------------------------------------\n",
      "XGBoost (log target):\n",
      "  RMSE: 922.53\n",
      "  MAE:  627.65\n",
      "  RÂ²:   -0.1692\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_log(name, model, X_test, y_test_log, y_true):\n",
    "    y_pred_log = model.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)  # inverse of log1p\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{name} (log target):\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    return {'Model': name, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "results_log = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_log, y_train_log)\n",
    "    result = evaluate_model_log(name, model, X_test_log, y_test_log, y_test)\n",
    "    results_log.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sqrt = np.sqrt(y)\n",
    "\n",
    "# Split again\n",
    "X_train_sqrt, X_test_sqrt, y_train_sqrt, y_test_sqrt = train_test_split(\n",
    "    X_processed, y_sqrt, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22104629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_sqrt(name, model, X_test, y_test_transformed, y_true):\n",
    "    y_pred_transformed = model.predict(X_test)\n",
    "    y_pred = np.square(y_pred_transformed)  # reverse sqrt\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{name} (sqrt target):\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    return {'Model': name, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (sqrt target):\n",
      "  RMSE: 868.96\n",
      "  MAE:  632.57\n",
      "  RÂ²:   -0.0374\n",
      "----------------------------------------\n",
      "Decision Tree (sqrt target):\n",
      "  RMSE: 1231.07\n",
      "  MAE:  906.08\n",
      "  RÂ²:   -1.0821\n",
      "----------------------------------------\n",
      "Random Forest (sqrt target):\n",
      "  RMSE: 861.37\n",
      "  MAE:  624.91\n",
      "  RÂ²:   -0.0193\n",
      "----------------------------------------\n",
      "XGBoost (sqrt target):\n",
      "  RMSE: 860.18\n",
      "  MAE:  620.75\n",
      "  RÂ²:   -0.0165\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results_sqrt = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_sqrt, y_train_sqrt)\n",
    "    result = evaluate_model_sqrt(name, model, X_test_sqrt, y_test_sqrt, y_test)\n",
    "    results_sqrt.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea2e4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "# Only works if target is strictly > 0\n",
    "y_boxcox, lam = boxcox(y)\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    X_processed, y_boxcox, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import inv_boxcox\n",
    "\n",
    "def evaluate_model_boxcox(name, model, X_test, y_test_transformed, y_true, lam):\n",
    "    y_pred_transformed = model.predict(X_test)\n",
    "    y_pred = inv_boxcox(y_pred_transformed, lam)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{name} (boxcox target):\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    return {'Model': name, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b70babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (boxcox target):\n",
      "  RMSE: 875.64\n",
      "  MAE:  630.88\n",
      "  RÂ²:   -0.0534\n",
      "----------------------------------------\n",
      "Decision Tree (boxcox target):\n",
      "  RMSE: 1231.30\n",
      "  MAE:  904.76\n",
      "  RÂ²:   -1.0829\n",
      "----------------------------------------\n",
      "Random Forest (boxcox target):\n",
      "  RMSE: 869.89\n",
      "  MAE:  622.45\n",
      "  RÂ²:   -0.0396\n",
      "----------------------------------------\n",
      "XGBoost (boxcox target):\n",
      "  RMSE: 867.33\n",
      "  MAE:  619.11\n",
      "  RÂ²:   -0.0335\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results_boxcox = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_b, y_train_b)\n",
    "    result = evaluate_model_boxcox(name, model, X_test_b, y_test_b, y_test, lam)\n",
    "    results_boxcox.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "658ceb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNone of the transformations gave a positive RÂ², butâ€¦\\n\\nBox-Cox with XGBoost yielded the lowest MAE and smoothest RMSE\\n\\nSqrt had slightly better RÂ² but not meaningfully\\n\\nSo while neither transformation made the model great, XGBoost with Box-Cox is still best-performing model overall.\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "None of the transformations gave a positive RÂ², butâ€¦\n",
    "\n",
    "Box-Cox with XGBoost yielded the lowest MAE and smoothest RMSE\n",
    "\n",
    "Sqrt had slightly better RÂ² but not meaningfully\n",
    "\n",
    "So while neither transformation made the model great, XGBoost with Box-Cox is still best-performing model overall.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ridge\n",
    "ridge_params = {'alpha': [0.1, 1, 10, 50, 100]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "ridge_best = ridge_grid.best_estimator_\n",
    "\n",
    "# Lasso\n",
    "lasso_params = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "lasso_grid = GridSearchCV(Lasso(max_iter=10000), lasso_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "lasso_best = lasso_grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "925ec4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (tuned):\n",
      "  RMSE: 852.11\n",
      "  MAE:  657.43\n",
      "  RÂ²:   0.0025\n",
      "----------------------------------------\n",
      "Lasso (tuned):\n",
      "  RMSE: 852.10\n",
      "  MAE:  657.44\n",
      "  RÂ²:   0.0025\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'Lasso (tuned)',\n",
       " 'RMSE': np.float64(852.0987759896539),\n",
       " 'MAE': 657.4423447535997,\n",
       " 'R2': 0.002503397084087644}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    return {'Model': name, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "evaluate_model(\"Ridge (tuned)\", ridge_best, X_test, y_test)\n",
    "evaluate_model(\"Lasso (tuned)\", lasso_best, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "249e7030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\nRidge and Lasso donâ€™t improve performance â€” they behave nearly identically to plain Linear Regression.\\n\\nXGBoost (boxcox) remains the best model in terms of absolute error (MAE), even though RÂ² is low.\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''\n",
    "Ridge and Lasso donâ€™t improve performance â€” they behave nearly identically to plain Linear Regression.\n",
    "\n",
    "XGBoost (boxcox) remains the best model in terms of absolute error (MAE), even though RÂ² is low.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e28e392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npickle is a Python module that:\\n\\nSerializes any Python object (like ML models, arrays, dictionaries)\\n\\nSaves them to a file\\n\\nLets you load them later without retraining\\n\\nWhy use it?\\n\\nTo deploy models in production (e.g., in Streamlit)\\n\\nTo share models without needing code retraining\\n\\nTo load models fast during inference\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pickle is a Python module that:\n",
    "\n",
    "Serializes any Python object (like ML models, arrays, dictionaries)\n",
    "\n",
    "Saves them to a file\n",
    "\n",
    "Lets you load them later without retraining\n",
    "\n",
    "Why use it?\n",
    "\n",
    "To deploy models in production (e.g., in Streamlit)\n",
    "\n",
    "To share models without needing code retraining\n",
    "\n",
    "To load models fast during inference\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6badb5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models saved as .pkl files âœ…\n"
     ]
    }
   ],
   "source": [
    "# Save All Models\n",
    "import pickle\n",
    "\n",
    "models_dict = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": ridge_best,\n",
    "    \"Lasso\": lasso_best,\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "# Fit each model (without target transformation) and save\n",
    "for name, model in models_dict.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    with open(f'{name}_model.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "print(\"All models saved as .pkl files âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8a18d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best model pipeline + lambda saved\n"
     ]
    }
   ],
   "source": [
    "#Save Best Model Pipeline (XGBoost + Preprocessor + Box-Cox)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "# Boxcox transformation\n",
    "y_boxcox, lam = boxcox(y)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    X_processed, y_boxcox, test_size=0.2, random_state=42)\n",
    "\n",
    "# Re-train best model on full data\n",
    "xgb_model = XGBRegressor(random_state=42, verbosity=0)\n",
    "xgb_model.fit(X_train_b, y_train_b)\n",
    "\n",
    "# Final pipeline (preprocessor only handles X)\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])\n",
    "\n",
    "# Save model and lambda for inverse transform later\n",
    "with open('final_best_model_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "with open('boxcox_lambda.pkl', 'wb') as f:\n",
    "    pickle.dump(lam, f)\n",
    "\n",
    "print(\"âœ… Best model pipeline + lambda saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5be8839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-3.1.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==3.1.4 (from mlflow)\n",
      "  Downloading mlflow_skinny-3.1.4-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: matplotlib<4 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from mlflow) (2.3.1)\n",
      "Requirement already satisfied: pandas<3 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from mlflow) (2.3.1)\n",
      "Collecting pyarrow<21,>=4.0.0 (from mlflow)\n",
      "  Using cached pyarrow-20.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from mlflow) (1.7.0)\n",
      "Requirement already satisfied: scipy<2 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from mlflow) (1.16.0)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading sqlalchemy-2.0.42-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading databricks_sdk-0.61.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<26 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from mlflow-skinny==3.1.4->mlflow) (25.0)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3,>=1.10.8 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from mlflow-skinny==3.1.4->mlflow) (6.0.2)\n",
      "Collecting requests<3,>=2.17.3 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting typing-extensions<5,>=4.0.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==3.1.4->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pywin32>=304 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (311)\n",
      "Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jinja2>=3.1.2 (from Flask<4->mlflow)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe>=2.1.1 (from Flask<4->mlflow)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.1.4->mlflow)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow)\n",
      "  Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\course\\aamir\\project 3\\coding\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.1.4->mlflow)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading mlflow-3.1.4-py3-none-any.whl (24.7 MB)\n",
      "   ---------------------------------------- 0.0/24.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/24.7 MB 3.5 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.0/24.7 MB 3.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.6/24.7 MB 2.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 2.6/24.7 MB 2.6 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 3.4/24.7 MB 3.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 3.9/24.7 MB 2.7 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 4.5/24.7 MB 2.7 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 5.5/24.7 MB 3.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 6.6/24.7 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 7.6/24.7 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 7.9/24.7 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 8.1/24.7 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 9.4/24.7 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.0/24.7 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.2/24.7 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 11.0/24.7 MB 3.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 11.8/24.7 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 12.6/24.7 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.4/24.7 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/24.7 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.2/24.7 MB 3.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.7/24.7 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 15.5/24.7 MB 3.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 16.3/24.7 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.3/24.7 MB 3.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.8/24.7 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.1/24.7 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.1/24.7 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.2/24.7 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.2/24.7 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.8/24.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.5/24.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/24.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.7/24.7 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-3.1.4-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.0/1.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading databricks_sdk-0.61.0-py3-none-any.whl (680 kB)\n",
      "   ---------------------------------------- 0.0/680.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 680.6/680.6 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached pyarrow-20.0.0-cp313-cp313-win_amd64.whl (25.7 MB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.0/2.0 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.42-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.1/2.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl (297 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: zipp, waitress, urllib3, typing-extensions, sqlparse, sniffio, smmap, pyasn1, pyarrow, protobuf, markupsafe, itsdangerous, idna, h11, greenlet, graphql-core, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, annotated-types, werkzeug, uvicorn, typing-inspection, sqlalchemy, rsa, requests, pydantic-core, pyasn1-modules, Mako, jinja2, importlib_metadata, graphql-relay, gitdb, anyio, starlette, pydantic, opentelemetry-api, graphene, google-auth, gitpython, Flask, docker, alembic, opentelemetry-semantic-conventions, fastapi, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "\n",
      "   ----------------------------------------  0/52 [zipp]\n",
      "    ---------------------------------------  1/52 [waitress]\n",
      "    ---------------------------------------  1/52 [waitress]\n",
      "    ---------------------------------------  1/52 [waitress]\n",
      "    ---------------------------------------  1/52 [waitress]\n",
      "    ---------------------------------------  1/52 [waitress]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   - --------------------------------------  2/52 [urllib3]\n",
      "   --- ------------------------------------  4/52 [sqlparse]\n",
      "   --- ------------------------------------  4/52 [sqlparse]\n",
      "   --- ------------------------------------  4/52 [sqlparse]\n",
      "   --- ------------------------------------  4/52 [sqlparse]\n",
      "   --- ------------------------------------  4/52 [sqlparse]\n",
      "   --- ------------------------------------  5/52 [sniffio]\n",
      "   ---- -----------------------------------  6/52 [smmap]\n",
      "   ---- -----------------------------------  6/52 [smmap]\n",
      "   ----- ----------------------------------  7/52 [pyasn1]\n",
      "   ----- ----------------------------------  7/52 [pyasn1]\n",
      "   ----- ----------------------------------  7/52 [pyasn1]\n",
      "   ----- ----------------------------------  7/52 [pyasn1]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  8/52 [pyarrow]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------ ---------------------------------  9/52 [protobuf]\n",
      "   ------- -------------------------------- 10/52 [markupsafe]\n",
      "   -------- ------------------------------- 11/52 [itsdangerous]\n",
      "   --------- ------------------------------ 12/52 [idna]\n",
      "   --------- ------------------------------ 12/52 [idna]\n",
      "   ---------- ----------------------------- 13/52 [h11]\n",
      "   ---------- ----------------------------- 13/52 [h11]\n",
      "   ---------- ----------------------------- 14/52 [greenlet]\n",
      "   ---------- ----------------------------- 14/52 [greenlet]\n",
      "   ---------- ----------------------------- 14/52 [greenlet]\n",
      "   ---------- ----------------------------- 14/52 [greenlet]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ----------- ---------------------------- 15/52 [graphql-core]\n",
      "   ------------ --------------------------- 16/52 [cloudpickle]\n",
      "   ------------- -------------------------- 17/52 [click]\n",
      "   ------------- -------------------------- 17/52 [click]\n",
      "   ------------- -------------------------- 17/52 [click]\n",
      "   ------------- -------------------------- 18/52 [charset_normalizer]\n",
      "   ------------- -------------------------- 18/52 [charset_normalizer]\n",
      "   ------------- -------------------------- 18/52 [charset_normalizer]\n",
      "   ------------- -------------------------- 18/52 [charset_normalizer]\n",
      "   ------------- -------------------------- 18/52 [charset_normalizer]\n",
      "   --------------- ------------------------ 20/52 [cachetools]\n",
      "   ---------------- ----------------------- 21/52 [blinker]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ----------------- ---------------------- 23/52 [werkzeug]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------ --------------------- 24/52 [uvicorn]\n",
      "   ------------------- -------------------- 25/52 [typing-inspection]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 26/52 [sqlalchemy]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   -------------------- ------------------- 27/52 [rsa]\n",
      "   --------------------- ------------------ 28/52 [requests]\n",
      "   --------------------- ------------------ 28/52 [requests]\n",
      "   --------------------- ------------------ 28/52 [requests]\n",
      "   ---------------------- ----------------- 29/52 [pydantic-core]\n",
      "   ---------------------- ----------------- 29/52 [pydantic-core]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 30/52 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ----------------------- ---------------- 31/52 [Mako]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------ --------------- 32/52 [jinja2]\n",
      "   ------------------------- -------------- 33/52 [importlib_metadata]\n",
      "   ------------------------- -------------- 33/52 [importlib_metadata]\n",
      "   -------------------------- ------------- 34/52 [graphql-relay]\n",
      "   -------------------------- ------------- 34/52 [graphql-relay]\n",
      "   -------------------------- ------------- 35/52 [gitdb]\n",
      "   -------------------------- ------------- 35/52 [gitdb]\n",
      "   -------------------------- ------------- 35/52 [gitdb]\n",
      "   -------------------------- ------------- 35/52 [gitdb]\n",
      "   -------------------------- ------------- 35/52 [gitdb]\n",
      "   --------------------------- ------------ 36/52 [anyio]\n",
      "   --------------------------- ------------ 36/52 [anyio]\n",
      "   --------------------------- ------------ 36/52 [anyio]\n",
      "   --------------------------- ------------ 36/52 [anyio]\n",
      "   --------------------------- ------------ 36/52 [anyio]\n",
      "   --------------------------- ------------ 36/52 [anyio]\n",
      "   --------------------------- ------------ 36/52 [anyio]\n",
      "   ---------------------------- ----------- 37/52 [starlette]\n",
      "   ---------------------------- ----------- 37/52 [starlette]\n",
      "   ---------------------------- ----------- 37/52 [starlette]\n",
      "   ---------------------------- ----------- 37/52 [starlette]\n",
      "   ---------------------------- ----------- 37/52 [starlette]\n",
      "   ---------------------------- ----------- 37/52 [starlette]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ----------------------------- ---------- 38/52 [pydantic]\n",
      "   ------------------------------ --------- 39/52 [opentelemetry-api]\n",
      "   ------------------------------ --------- 39/52 [opentelemetry-api]\n",
      "   ------------------------------ --------- 39/52 [opentelemetry-api]\n",
      "   ------------------------------ --------- 39/52 [opentelemetry-api]\n",
      "   ------------------------------ --------- 39/52 [opentelemetry-api]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------ --------- 40/52 [graphene]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   ------------------------------- -------- 41/52 [google-auth]\n",
      "   -------------------------------- ------- 42/52 [gitpython]\n",
      "   -------------------------------- ------- 42/52 [gitpython]\n",
      "   -------------------------------- ------- 42/52 [gitpython]\n",
      "   -------------------------------- ------- 42/52 [gitpython]\n",
      "   -------------------------------- ------- 42/52 [gitpython]\n",
      "   -------------------------------- ------- 42/52 [gitpython]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 43/52 [Flask]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   --------------------------------- ------ 44/52 [docker]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ---------------------------------- ----- 45/52 [alembic]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------- --- 46/52 [opentelemetry-semantic-conventions]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 47/52 [fastapi]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------ --- 48/52 [databricks-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 49/52 [opentelemetry-sdk]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   -------------------------------------- - 50/52 [mlflow-skinny]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------  51/52 [mlflow]\n",
      "   ---------------------------------------- 52/52 [mlflow]\n",
      "\n",
      "Successfully installed Flask-3.1.1 Mako-1.3.10 alembic-1.16.4 annotated-types-0.7.0 anyio-4.10.0 blinker-1.9.0 cachetools-5.5.2 certifi-2025.8.3 charset_normalizer-3.4.2 click-8.2.1 cloudpickle-3.1.1 databricks-sdk-0.61.0 docker-7.1.0 fastapi-0.116.1 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.40.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.3 h11-0.16.0 idna-3.10 importlib_metadata-8.7.0 itsdangerous-2.2.0 jinja2-3.1.6 markupsafe-3.0.2 mlflow-3.1.4 mlflow-skinny-3.1.4 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 protobuf-6.31.1 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.4 rsa-4.9.1 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.42 sqlparse-0.5.3 starlette-0.47.2 typing-extensions-4.14.1 typing-inspection-0.4.1 urllib3-2.5.0 uvicorn-0.35.0 waitress-3.0.2 werkzeug-3.1.3 zipp-3.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f785609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 17:02:49 INFO mlflow.tracking.fluent: Experiment with name 'SmartPremium_Prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 29 features, but ColumnTransformer is expecting 18 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m mlflow.log_param(\u001b[33m\"\u001b[39m\u001b[33mboxcox_lambda\u001b[39m\u001b[33m\"\u001b[39m, lam)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Predict and inverse transform\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m y_pred_boxcox = \u001b[43mfinal_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m y_pred = inv_boxcox(y_pred_boxcox, lam)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Metrics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Course\\Aamir\\project 3\\coding\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:786\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict(Xt, **params)\n\u001b[32m    789\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Course\\Aamir\\project 3\\coding\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Course\\Aamir\\project 3\\coding\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1089\u001b[39m, in \u001b[36mColumnTransformer.transform\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m   1085\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1087\u001b[39m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[32m   1088\u001b[39m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[32m   1092\u001b[39m     routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Course\\Aamir\\project 3\\coding\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2840\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2842\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 29 features, but ColumnTransformer is expecting 18 features as input."
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "# Start tracking\n",
    "mlflow.set_experiment(\"SmartPremium_Prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_BoxCox\"):\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"boxcox_lambda\", lam)\n",
    "\n",
    "    # Predict and inverse transform\n",
    "    y_pred_boxcox = final_pipeline.predict(X_test)\n",
    "    y_pred = inv_boxcox(y_pred_boxcox, lam)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(final_pipeline, \"final_model_pipeline\")\n",
    "\n",
    "    print(f\"âœ… Run logged in MLflow with RMSE={rmse:.2f}, MAE={mae:.2f}, RÂ²={r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d085099",
   "metadata": {},
   "source": [
    "ML FLOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 17:07:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/05 17:08:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Run logged in MLflow with RMSE=867.33, MAE=619.11, RÂ²=-0.0335\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "# Use original test data (before preprocessing)\n",
    "X_raw = df.drop(columns=['Premium Amount'])\n",
    "_, X_test_raw, _, y_test_raw = train_test_split(X_raw, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlflow.set_experiment(\"SmartPremium_Prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_BoxCox\"):\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"boxcox_lambda\", lam)\n",
    "\n",
    "    y_pred_boxcox = final_pipeline.predict(X_test_raw)\n",
    "    y_pred = inv_boxcox(y_pred_boxcox, lam)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_raw, y_pred))  # <-- fix here\n",
    "    mae = mean_absolute_error(y_test_raw, y_pred)\n",
    "    r2 = r2_score(y_test_raw, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "    mlflow.sklearn.log_model(final_pipeline, \"final_model_pipeline\")\n",
    "\n",
    "    print(f\"âœ… Run logged in MLflow with RMSE={rmse:.2f}, MAE={mae:.2f}, RÂ²={r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dca7c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 17:43:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/05 17:43:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logged: LinearRegression | RMSE=852.11, MAE=657.43, RÂ²=0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 17:43:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/05 17:44:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logged: Ridge | RMSE=852.11, MAE=657.43, RÂ²=0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 17:44:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/05 17:44:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logged: Lasso | RMSE=852.10, MAE=657.44, RÂ²=0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 17:44:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/05 17:44:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logged: XGBoost_raw | RMSE=841.97, MAE=642.83, RÂ²=0.0261\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mlflow.set_experiment(\"SmartPremium_Prediction\")\n",
    "\n",
    "models_dict = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": ridge_best,\n",
    "    \"Lasso\": lasso_best,\n",
    "    \"XGBoost_raw\": XGBRegressor(random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "\n",
    "        # If Ridge or Lasso, log alpha\n",
    "        if hasattr(model, 'alpha'):\n",
    "            mlflow.log_param(\"alpha\", model.alpha)\n",
    "\n",
    "        # Fit on original target\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"âœ… Logged: {name} | RMSE={rmse:.2f}, MAE={mae:.2f}, RÂ²={r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7222d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
